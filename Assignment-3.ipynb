{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fashion mnist dataset\n",
    "df = pd.read_csv('./datasets/fashion-mnist_train.csv')\n",
    "fmnist_data = df.values[:40000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes [0 1 2 3 4 5 6 7 8 9] \n",
      "Number of classes 10\n"
     ]
    }
   ],
   "source": [
    "# number of classes\n",
    "cls = np.unique(fmnist_data[:,0])\n",
    "print(\"Classes {} \\nNumber of classes {}\".format(cls,len(cls)))\n",
    "# number of features is 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "ratio = 0.8\n",
    "m = fmnist_data.shape[0]\n",
    "train = fmnist_data[:int(m*ratio),:]\n",
    "test = fmnist_data[int(m*ratio):,:]\n",
    "\n",
    "# training data\n",
    "X_train = train[:,1:]\n",
    "y_train = train[:,0]\n",
    "\n",
    "# testing data\n",
    "X_test = test[:,1:]\n",
    "y_test = test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFJCAYAAAASfw+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFUhJREFUeJzt3X9sVfX9x/HXtZShvdQO0eBWgRYEQy+OEILZBpjoKoYoSIIiEEgsicI0WBVEiw5Mb8QF/YstZBI1ETWzYpbwh0ydCTYKY8at0NZUnHMmQGVUkPZW4N7Ssz++Wb/cy72n73Pb++Mcn4+kieecTz/n8+4pL0/vuZ/7CTmO4wgA4OqyQg8AAPyAsAQAA8ISAAwISwAwICwBwICwBAALJw8kpf1qbW3NeMyvX9Tkn68g1hXEmvJZl5tQPt5nGQqF0u53HCfjMb+iJv8IYl1BrEnKX11ucTgimw77+/u1ZcsWff755xo5cqSi0agmTJiQ9QABoNhl9ZrlX/7yF8Xjcb355pt67LHH9Nxzzw33uACgqGQVlp9++qnmzp0rSZoxY4ba2tqGdVAAUGyy+jM8FospHA4PbJeUlKivr08jRqTvrrW1VZFIJO2xPLxkmnfU5B9BrCuINUmFryursAyHw+rt7R3Y7u/vzxiUkjR9+vS0+4P4YjQ1+UcQ6wpiTVJxPODJ6s/wmTNnqrm5WZLU0tKiKVOmZDcyAPCJrO4sa2tr9fHHH+vee++V4zh69tlnh3tcAFBUeJ/lMKMm/whiXUGsSfLxn+EA8ENDWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgMCLbb7zrrrs0evRoSVJlZaW2bt06bIMCgGKTVVieP39ekrRr165hHQwAFKus/gzv6OjQ2bNnVVdXp1WrVqmlpWW4xwUAxcXJQkdHh/Pmm286/f39zr/+9S/n1ltvdRKJRMb2ktJ+uR3z6xc1+ecriHUFsaZ81uUmqz/Dq6qqNGHCBIVCIVVVVamiokInT57Utddem7Z9a2urIpFI2mP/9zMIFmryjyDWFcSapMLXlVVY7t69W0eOHNGWLVt04sQJxWIxXX311RnbT58+Pe1+x3EUCoWyGULRoib/CGJdQaxJyl9dboEccrKI63g8rieffFLHjx9XKBTS+vXrNXPmzMwnyVBkEC8sNflHEOsKYk2Sj8PSK8LS34JYkxTMuoJYk1QcYcmb0gHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwGBEoQcAfyotLTW3TSQSw37+qVOnmtteddVVGY/94he/yKrfV155xXx+L0KhkLmt4zg5GcNwy9XvSk1NjaldZ2enuU833FkCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABkx3/AHIxRS6XExhlKQXXnjB1G7dunXmPs+dO5fx2Lvvvpu0/e9//9vUZ09Pj/n8u3fvNrfNxRTGyy6z3xN5OX+hf1fyPd2TO0sAMDCF5aFDh7Ry5UpJ0tdff61ly5Zp+fLl2rx5s/r7+3M6QAAoBoOG5c6dO/XUU0/p/PnzkqStW7eqvr5eb7zxhhzH0QcffJDzQQJAoQ0aluPHj9f27dsHttvb2zV79mxJ0rx587R///7cjQ4AisSgD3jmz5+vo0ePDmw7jjPwwKCsrMz0Qndra6sikUjaY375TD4vqKm4hMNh87FMv6ep3nrrrSGNKZf8fK3cFLouz0/DL36y1tvbq/Ly8kG/Z/r06Wn3Xxy8QVGMNQ31aXg+a8rn0/BwOKxYLJa0z/o0/JlnnjGf38vT8KFKd60K/TR8OKSra9q0aabv/eabb8zn+fbbbzMe8/w0fNq0aTp48KAkqbm5WbNmzfLaBQD4juew3Lhxo7Zv366lS5cqkUho/vz5uRgXABQV05/hlZWVampqkiRVVVXptddey+mgAKDYMIPnByAXry3NmzfP3HbXrl3mtuPGjTO1e+edd8x9fvnll2n3P/LII9q5c2fSvlGjRpn63Lx5s/n8t9xyi7ntr3/9a3NbKz+9F9rt9yr12P9u4AZj/Z0aDDN4AMCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPfTnf08pFhXj6iyqq0tDTjsdQpc24LZmXrmmuuMbe97bbbzG0zffTZ3/72t6TtGTNmmPvs6Ogwt/3zn/9sajdihP1X1226W+qx0aNHm/o8deqU+fyLFi3KSds9e/ak3b9jx46k7b///e/mPq3TPSX7Z3/+6le/MvdZUVGR8dif/vSnpG1rBnipyQ13lgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoBByMnF0n+pJ8kwLclxHE/TFv1gqDX94Q9/MLVbsGCBuc/u7m5z23TT+ObMmaOPPvooaV9nZ6e5z66uLnPbCxcumNpdddVV5j4nTZqUdv/s2bMvmcY5ZswYU59eprBaa5Kk8vJyc9t0P4Py8vJLrreX6b4lJSXmtlbHjx83t80UR5MnT9Y///nPpH2VlZWmPhcuXGg+/3vvvZfxGHeWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBg4NsFy7y4/PLLzW0zzfZI9ctf/jLjsQceeCBpe+nSpebz9/f3m9p5WYTqu+++G1LbOXPmXHK+s2fPmvt0W4Qq1bXXXmtqN3HiRHOfboubXXHFFUnbsVjM1KeXWTGJRMLc9vTp0+a233zzzSX7fv7zn6u9vT1pn9viekPR19dnaufl/D/60Y8yHkudNWWdKTdr1izz+d1wZwkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAY5GW6o9siSKnHXn75ZVOfc+fONZ+/p6fH3NY6Nc1tWtZDDz2UtJ1uWlom1rZeFpZqaWkxt43H42n3HzlyJGl7ypQp5j6vvPJKc1vrgl1eFkFzm2737bffJm3nYsGu8+fPm9t6Wdws0881dSqmlwX0ent7zW3dppFezO3fSiq3qcmpx6xrLXqZGuuGO0sAMDCF5aFDh7Ry5UpJUnt7u+bOnauVK1dq5cqVeuedd3I6QAAoBoPeR+/cuVN79uwZuAX+7LPPdN9996muri7ngwOAYjHoneX48eO1ffv2ge22tjbt27dPK1asUENDg/kjrQDAz0KO4VXSo0eP6tFHH1VTU5PefvttTZ06VZFIRDt27FB3d7c2btzo+v1tbW2KRCLDNmgAyDfPT8Nra2sHnljW1taqsbFx0O+ZMWNG2v19fX2XPFHz+9PwSCSitra2pH2Ffhr+ySefmNumexr+u9/97pIn/F6ehl9zzTXD3tb6IclS5qfhN998sz788MOkfX5/Gn7TTTfp4MGDSfusT62l3DwNt77DQcr8NHzSpEn68ssvk/b99Kc/NfX56quvms9///33Zzzm+Wn46tWrdfjwYUnSgQMHVFNT47ULAPAdz3eWW7ZsUWNjo0pLSzV27FjTnSUA+J0pLCsrK9XU1CRJqqmp0R//+MecDgoAig1vSgcAg7xMd3R7ITj1WGdnp6nP999/33x+64qB6caTSabV/SKRiI4dO5a0z8vqduPGjTO1+89//mPu85ZbbjG3zfRi/D333JO07WUKmZf6U6cfZjJq1Chzn25trat5phozZoy5rZeVIK1T+KTM0xh/9rOfmfuw9pmO9WGYlwdMbqtbpv7MR44caeozdQXPbHFnCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABiYPvx3qDKtQnfmzJlLjnV3d+d6OMNi9OjRafd3d3dfMmXQy5S6H//4x6Z2XqaQDbXtnj17tHDhwqR9Xqbwua3Yl6qysnLY+8w0Le6pp55SNBpN2mf95+BlhYBTp06Z23r55/j9999fsu+NN97Q8uXLzX2k+u6778xt3aYmZtvnyZMn0+7v6urS2LFjk/ZVVFQMqc90zpw5k/EYd5YAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGCQlxk8mRaMOnfu3CXHMi2YlcrLDJLe3l5z23Pnzpna9fX1pd3vOI6nRZ/8IIg1ScGsy+81ZZqZ9f3331+y8FhVVZWpTy9Z0dramrkfcy8A8ANGWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgIF9JashOH/+vPmYdXEhL1OYvCzYlWkhslT9/f0Zj2VaoM2ipKRkWNtJ3n5WpaWlafenLiSWaRGwdNx+VqkyTSNN5WVKn9uMXusCaV76TDVcY7W2/clPfpJ1n15+r6zXNR6Pm/u8cOFCxmOpU6PdFhe72IkTJ8znd8OdJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGCQl9UdM0338vtKdOlQk38Esa4g1iTlry63OOTOEgAMXD9hIpFIqKGhQceOHVM8HtfatWs1efJkPfHEEwqFQrr++uu1efNmTx/UAAB+5BqWe/bsUUVFhbZt26bTp09r8eLFuuGGG1RfX6+bbrpJv/nNb/TBBx+otrY2X+MFgIJwvSW8/fbb9fDDDw9sl5SUqL29XbNnz5YkzZs3T/v378/tCAGgCLjeWZaVlUmSYrGY1q1bp/r6ev32t78deKG1rKxMPT09g56ktbVVkUgk7bE8PF/KO2ryjyDWFcSapMLXNein4nZ2durBBx/U8uXLdeedd2rbtm0Dx3p7e1VeXj7oSaZPn552fxCf3FGTfwSxriDWJPngaXhXV5fq6uq0YcMGLVmyRJI0bdo0HTx4UJLU3NysWbNmDeNQAaA4ub7PMhqNau/evaqurh7Yt2nTJkWjUSUSCVVXVysajQ76UfS8z9LfgliTFMy6gliTVBx3lrwpfZhRk38Esa4g1iQVR1jyBkkAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAY4XYwkUiooaFBx44dUzwe19q1azVu3DitWbNGEydOlCQtW7ZMCxYsyMdYAaBgQo7jOJkOvv322+ro6NCmTZt0+vRpLV68WA8++KB6enpUV1dnP0kolHa/4zgZj/kVNflHEOsKYk1S/upyiUP3sOzt7ZXjOAqHwzp9+rSWLFmiOXPm6KuvvtKFCxc0YcIENTQ0KBwOuw6AsPS3INYkBbOuINYk+SAs/ycWi2nt2rW65557FI/HNXXqVEUiEe3YsUPd3d3auHGj6/e3tbUpEol4HzkAFAtnEMePH3cWL17svPXWW47jOM6ZM2cGjn3xxRfOqlWrBuvCkZT2y+2YX7+oyT9fQawriDXlsy43rk/Du7q6VFdXpw0bNmjJkiWSpNWrV+vw4cOSpAMHDqimpsatCwAIBNc/w6PRqPbu3avq6uqBffX19dq2bZtKS0s1duxYNTY28prlRajJP4JYVxBrkvJX15BfsxwqwtLfgliTFMy6gliTVBxhyZvSAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAIO8LIULAH7HnSUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYDAi3yfs7+/Xli1b9Pnnn2vkyJGKRqOaMGFCvoeRE3fddZdGjx4tSaqsrNTWrVsLPKLsHTp0SM8//7x27dqlr7/+Wk888YRCoZCuv/56bd68WZdd5r//z15cU3t7u9asWaOJEydKkpYtW6YFCxYUdoAeJRIJNTQ06NixY4rH41q7dq0mT57s62uVrqZx48YVx7Vy8uzdd991Nm7c6DiO4/zjH/9w1qxZk+8h5MS5c+ecRYsWFXoYw+LFF1907rjjDufuu+92HMdxHnjgAeevf/2r4ziO8/TTTzvvvfdeIYeXldSampqanJdeeqnAoxqa3bt3O9Fo1HEcxzl16pRz8803+/5apaupWK5V3v+X8+mnn2ru3LmSpBkzZqitrS3fQ8iJjo4OnT17VnV1dVq1apVaWloKPaSsjR8/Xtu3bx/Ybm9v1+zZsyVJ8+bN0/79+ws1tKyl1tTW1qZ9+/ZpxYoVamhoUCwWK+DosnP77bfr4YcfHtguKSnx/bVKV1OxXKu8h2UsFlM4HB7YLikpUV9fX76HMexGjRql1atX66WXXtIzzzyj9evX+7au+fPna8SI/3+FxnEchUIhSVJZWZl6enoKNbSspdZ044036vHHH9frr7+u6667Tr///e8LOLrslJWVKRwOKxaLad26daqvr/f9tUpXU7Fcq7yHZTgcVm9v78B2f39/0i+xX1VVVWnhwoUKhUKqqqpSRUWFTp48WehhDYuLX/Pq7e1VeXl5AUczPGpraxWJRAb++7PPPivwiLLT2dmpVatWadGiRbrzzjsDca1SayqWa5X3sJw5c6aam5slSS0tLZoyZUq+h5ATu3fv1nPPPSdJOnHihGKxmK6++uoCj2p4TJs2TQcPHpQkNTc3a9asWQUe0dCtXr1ahw8fliQdOHBANTU1BR6Rd11dXaqrq9OGDRu0ZMkSSf6/VulqKpZrlfcP0vjf0/AjR47IcRw9++yzmjRpUj6HkBPxeFxPPvmkjh8/rlAopPXr12vmzJmFHlbWjh49qkcffVRNTU366quv9PTTTyuRSKi6ulrRaFQlJSWFHqJnF9fU3t6uxsZGlZaWauzYsWpsbEx6ecgPotGo9u7dq+rq6oF9mzZtUjQa9e21SldTfX29tm3bVvBrxacOAYCBf96ABQAFRFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAY/BdU9sNzk1THVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# visualizing as picture\n",
    "def draw_image(sample):\n",
    "    img = sample.reshape((28,28))\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()\n",
    "draw_image(X_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing data\n",
    "X_train = (((X_train-X_train.min())*255)/(X_train.max()-X_train.min()))\n",
    "X_test = (((X_test-X_test.min())*255)/(X_test.max()-X_test.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized implemetation\n",
    "def hypothesis(X,theta): \n",
    "    return sigmoid(X@theta)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-1.0*z))\n",
    "    \n",
    "def error(X_t, y_t, theta):\n",
    "    h = hypothesis(X_t,theta)\n",
    "    return (-0.5*np.sum((y_t)*np.log(h)+(1-y_t)*np.log(1-h),axis=0))/X_t.shape[0];\n",
    "\n",
    "def gradient(X_t, y_t, theta):\n",
    "    return (np.transpose(X_t)@(hypothesis(X_t,theta)-y_t))/X_t.shape[0]\n",
    "\n",
    "def gradient_descent(X_t, y_t, alpha, max_itr=500, threshold =0.0001):\n",
    "    grad = np.zeros((X_t.shape[1],1))\n",
    "    theta = np.zeros((X_t.shape[1],1))\n",
    "    err = []\n",
    "    acc = []\n",
    "    \n",
    "    for x in range(max_itr):\n",
    "        grad = gradient(X_t, y_t, theta)\n",
    "        theta = theta - alpha * grad\n",
    "        err.append(error(X_t, y_t, theta))\n",
    "        acc.append(accuracy(X_t, y_t, theta))\n",
    "        if len(err) > 1 and (abs(err[x]-err[x-1])) < threshold:\n",
    "            break\n",
    "    return (theta,err,acc)\n",
    "\n",
    "def gradient_batch_descent(X_t, y_t, alpha=0.01,max_itr=150, threshold=0.0001, batch_size=5):\n",
    "    grad = np.zeros((X_t.shape[1],1))\n",
    "    theta = np.zeros((X_t.shape[1],1))\n",
    "    err = []\n",
    "    t_err = []\n",
    "    t_acc = []\n",
    "    acc = []\n",
    "    m = X_t.shape[0]\n",
    "    for x in range(max_itr):\n",
    "        for i in range(int(m/batch_size)):\n",
    "            err = []\n",
    "            acc = []\n",
    "            grad = gradient(X_t[i*batch_size:(i+1)*batch_size,:], y_t[i*batch_size:(i+1)*batch_size],theta)\n",
    "            theta = theta - alpha*grad;\n",
    "            acc.append(accuracy(X_t, y_t, theta))\n",
    "            err.append(error(X_t[i*batch_size:(i+1)*batch_size,:], y_t[i*batch_size:(i+1)*batch_size],theta))\n",
    "        t_err.append(np.mean(err))\n",
    "        t_acc.append(np.mean(acc))\n",
    "        if len(t_err) > 1 and abs(np.mean(t_err[:])-np.mean(t_err[:-1])) <threshold:\n",
    "            break\n",
    "    return (theta,t_err,t_acc)\n",
    "\n",
    "def predict(X_t,theta):\n",
    "    return hypothesis(X_t,theta) > 0.5\n",
    "\n",
    "def accuracy(X_t,y_t,theta):\n",
    "    return np.sum(predict(X_t,theta)==y_t,axis=0)/(y_t.shape[0])\n",
    "\n",
    "# create all training sets based on labels\n",
    "def create_all_train(X_train,y_train):\n",
    "    list_all = [[],[],[],[],[],[],[],[],[],[]]\n",
    "    for i in range(y_train.shape[0]):\n",
    "        list_all[y_train[i]].append(X_train[i])\n",
    "    return np.array(list_all)\n",
    "\n",
    "def combine_two_train(x1,len1,x2,len2):\n",
    "    x = x1[0]\n",
    "    for i in range(1,len1):\n",
    "        x = np.vstack((x,x1[i]))\n",
    "    for i in range(0,len2):\n",
    "        x = np.vstack((x,x2[i]))\n",
    "    y = np.ones((len1,1))\n",
    "    y = np.vstack((y,np.zeros((len2,1))))\n",
    "    d = np.hstack((y,x))\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(d)\n",
    "    return d[:,1:], d[:,0]\n",
    "    \n",
    "def build_classifers(X_train,y_train,label):\n",
    "    list_all = create_all_train(X_train,y_train)\n",
    "    theta_classifier = []\n",
    "    for i in label:\n",
    "        for j in label:\n",
    "            if j==i:\n",
    "                continue\n",
    "            x_t,y_t = combine_two_train(list_all[i],len(list_all[i]),list_all[j],len(list_all[j]))\n",
    "            theta,err,acc = gradient_batch_descent(x_t,y_t.reshape((-1,1)))\n",
    "            theta_classifier.append((theta,i,j))\n",
    "    return np.array(theta_classifier)\n",
    "    \n",
    "\n",
    "def predict_test(theta_classifier,x):\n",
    "        list_predict = []\n",
    "        for i in range(theta_classifier.shape[0]):\n",
    "            pred = predict(x,theta_classifier[i][0])\n",
    "            if pred == 1:\n",
    "                list_predict.append(theta_classifier[i][1])\n",
    "            else:\n",
    "                list_predict.append(theta_classifier[i][2])\n",
    "        list_predict = np.array(list_predict)\n",
    "        index = stats.mode(list_predict).mode[0]\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akroh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/akroh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in multiply\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "theta_classifier = build_classifers(X_train[:4000,:],y_train[:4000],cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "p = predict_test(theta_classifier,X_test[3])\n",
    "print(y_test[3])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807875\n"
     ]
    }
   ],
   "source": [
    "# checking accuracy\n",
    "def accuracy_multi_classifier(theta_classifier,X_test,y_test):\n",
    "    acc = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        acc += (predict_test(theta_classifier,X_test[i])==y_test[i])\n",
    "    return acc/X_test.shape[0]\n",
    "\n",
    "accuracy = accuracy_multi_classifier(theta_classifier,X_test,y_test)\n",
    "print(accuracy)\n",
    "# for 100 examples\n",
    "# 66.6875 -- leave rem\n",
    "# 61.7 ish -- with rem\n",
    "# for 1000 examples\n",
    "# 78.675 -- leave rem **best**\n",
    "# 75.075 -- leave rem -- without randomize\n",
    "# 69.3 -- with rem \n",
    "# 66.6375 -- with rem -- without randomize\n",
    "# for 4000 examples\n",
    "# 80.7875 -- leave rem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLEARN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for ovo  6.110020160675049\n",
      "Score ovo 0.807125\n"
     ]
    }
   ],
   "source": [
    "ovo = OneVsOneClassifier(estimator=LogisticRegression(random_state=5))\n",
    "start = time.time()\n",
    "ovo.fit(X_train[:4000,:],y_train[:4000])\n",
    "end = time.time()\n",
    "print(\"time taken for ovo \",end-start)\n",
    "print(\"Score ovo\",ovo.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs Rest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for ovr  1.5276100635528564\n",
      "Score ovr 0.79\n"
     ]
    }
   ],
   "source": [
    "ovr = OneVsRestClassifier(estimator=LogisticRegression(random_state=5))\n",
    "start = time.time()\n",
    "ovr.fit(X_train[:1000,:],y_train[:1000])\n",
    "end = time.time()\n",
    "print(\"time taken for ovr \",end-start)\n",
    "print(\"Score ovr\",ovo.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1,x2):\n",
    "    return np.sqrt(sum((x1-x2)**2))\n",
    "\n",
    "def KNN(X,y,query,k=5):\n",
    "    dist = []\n",
    "    m = X.shape[0]\n",
    "    for i in range(m):\n",
    "        dist.append([euclidean_distance(X[i],query),y[i]])\n",
    "    \n",
    "    sorted_dist = sorted(dist)\n",
    "    dist_k = sorted_dist[:k]\n",
    "    dist_k = np.array(dist_k)\n",
    "    dist_k_tuple = np.unique(dist_k[:,1],return_counts=True)\n",
    "    res = dist_k_tuple[0][dist_k_tuple[1].argmax()]\n",
    "    return res\n",
    "        \n",
    "def accuracy_KNN(X_t,y_t,X_tst,y_tst):\n",
    "    mt = X_tst.shape[0]\n",
    "    y_pred = []\n",
    "    for i in range(mt):\n",
    "        y_pred.append(KNN(X_t,y_t,X_tst[i]))\n",
    "    return sum(y_pred==y_tst)/mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value 7\n",
      "actual value 7\n",
      "accuracy 0.752750\n"
     ]
    }
   ],
   "source": [
    "k = KNN(X_train[:100,:],y_train[:100],X_test[0])\n",
    "print(\"predicted value %d\"%k)\n",
    "print(\"actual value %d\"%y_test[0])\n",
    "print(\"accuracy %f\"%accuracy_KNN(X_train[:1000,:],y_train[:1000],X_test,y_test))\n",
    "# classifiaton accuracy is 0.752750 same as sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Implementation of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual value 7\n",
      "accuracy of sklearn KNN  0.75275\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "knn.fit(X_train[:1000,:],y_train[:1000])\n",
    "print(\"actual value %d\"%y_test[0])\n",
    "print(\"accuracy of sklearn KNN \",knn.score(X_test,y_test))\n",
    "# classifiaton accuracy is 0.752750 same as my algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
